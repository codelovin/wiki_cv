# Kaggle Humpback Whales Identification

Недавно моя команда приняла участие в соревновании по идентификации горбатых китов, которое проводилось в Kaggle. Мы выиграли золотую медаль и заняли 10-е место (из 2131 команды) на лидерборде. В этом реферате я кратко расскажу об основных идеях нашего решения.

## Описание проблемы
Основная цель состояла в том, чтобы определить, принадлежит ли данная фотография плавника кита одному из 5004 известных особей, или же это новый кит, никогда ранее не наблюдавшийся. Интересным аспектом этого соревнования был огромный дисбаланс классов. Для более чем 2000 классов был только один тренировочный пример, что затрудняло использование подхода классификации из коробки. Более того, важной частью конкурса было определение, является ли кит новым или нет, что оказалось довольно нетривиальной задачей.

## Валидация, работа с данными
Главной метрикой соревнования была mAP @ 5 (средняя точность 5), что позволило нам предоставлять до 5 прогнозов для каждого тестового изображения. Наш самый высокий результат на частном тестовом наборе был 0,959 mAP @ 5.

За пару месяцев до этого соревнования на Kaggle была организована Playground-версия того же соревнования, но, как отмечали организаторы, настоящая версия имела еще больше данных, а метки были более чистыми. Мы решили использовать знания и данные предыдущего конкурса различными способами
Используя данные предыдущего конкурса, мы использовали хеширование изображений для сбора более 2000 образцов для валидации. Мы удалили класс new_whale из обучающего набора данных, так как он не содержит логического смысла, который позволил бы сети отделить этот класс.

Некоторые изображения не были выровнены. К счастью, была общедоступная предварительно обученная модель детекции. Мы использовали ее, чтобы обнаружить точный bbox вокруг хвоста и соответственно обрезали изображения.
Из-за разной цветовой гаммы изображений все данные были преобразованы в grayscale перед тренировкой.

## Подход № 1: Сиамские сети
Нашей первой архитектурой была сиамская сеть с многочисленными backbone-архитектурами и нестандартным лоссом. Используемые нами архитектуры:
ResNet-18, ResNet-34, Resnet-50
SE-ResNeXt-50
ResNet-подобная кастомная сеть.

Мы использовали hard-negative и hard-positive mining, решая задачу LAP на матрице скоров каждые 4 эпохи. Матрица немного рандомизировалась чтобы облегчить обучение.

Использовалось прогрессивное обучение со стратегией 229x229 -> 384x384 -> 512x512. То есть мы сначала обучили нашу сеть 229x229 изображениям с небольшой регуляризацией и большей скоростью обучения. После конвергенции мы понижаем скорость обучения и увеличиваем регуляризацию, после чего обучаем сеть изображениям с более высоким разрешением (например, 384x484).
Аугментации состояли из: случайная яркость, гауссов шум и случайное размытие.
Еще одна аугментация связана с тем, что делая random_flip мы по сути меняем пару китов с верной на неверную.

Модели были оптимизированы с использованием оптимизатора Adam с начальной скоростью обучения 1e-4 уменьшали 5 раз на плато. Размер батча был равен 64.

Модели были написаны на Керасе и обучались около 2-3 дней на одной 2080Ti.


## Подход № 2: Метрическое обучение
Другим подходом, который мы использовали, было metric learning с Margin Loss. Мы использовали многочисленные предобученные архитектуры ImageNet, которые включали:
ResNet-50, ResNet-101, ResNet-152
DenseNet-121, DenseNet-169
Также использовалось прогрессивное обучение со стратегией 448x448 -> 672x672.

Мы использовали оптимизатор Adam, снижая скорость обучения в 10 раз каждые 100 эпох. Batch size был выбран равным 96 на протяжении всего обучения.

Из-за огромного дисбаланса классов были использованы суровые аугментации, которые включали random flip, поворот, масштабирование, размытие, освещение, контрастность, изменение насыщенности. Во время inference были вычислены L2 нормы между вектором тестового запроса и векторами объектов галереи, и в качестве прогноза ТОП-1 был выбран класс с наибольшим значением точечного произведения. Еще одна уловка, которая неявно помогла с дисбалансом классов, заключалась в усреднении векторов признаков для изображений китов, принадлежащих к тем же особям.
Модели были реализованы на PyTorch и требовали 2–4 дня (в зависимости от разрешения изображения) на одном Titan Xp.

## Подход № 3: Классификация по признакам
Мы также обучили модели классификации, используя ембеддинги, извлеченные из всех наших моделей и объединенные вместе (конечно, после применения PCA).
Голова для классификации состояла из двух полносвязных слоев с дропаутом между ними. Модель обучалась очень быстро, потому что мы использовали предварительно вычисленные ембеддинги.

Такой подход позволил нам получить еще более классный результат и внес еще больше разнообразия в общий ансамбль.
