# Kaggle Humpback Whales Identification

Недавно моя команда приняла участие в соревновании по идентификации горбатых китов, которое проводилось на Kaggle. Мы выиграли золотую медаль и заняли 10-е место (из 2131 команды) на лидерборде. В этом реферате я кратко расскажу об основных идеях нашего решения.

## Описание проблемы
Основная цель состояла в том, чтобы определить, принадлежит ли данная фотография плавника кита одной из 5004 известных особей, или же это новый кит, никогда ранее не наблюдавшийся. Интересным аспектом этого соревнования был огромный дисбаланс классов: Для более чем 2000 классов был только один тренировочный пример, что затрудняло использование подхода классификации из коробки. Более того, важной частью конкурса было определение, является ли кит новым или нет, что оказалось довольно нетривиальной задачей.

## Валидация, работа с данными
Главной метрикой соревнования была mAP @ 5, что позволило нам предоставлять до 5 прогнозов для каждого тестового изображения. Наш самый высокий результат на приватном тестовом сете был 0,959 mAP @ 5.

За пару месяцев до этого соревнования на Kaggle была организована Playground-версия того же соревнования, но, как отмечали организаторы, настоящая версия имела еще больше данных, а метки были более чистыми. Мы решили использовать знания и данные предыдущего конкурса различными способами
Используя данные предыдущего конкурса, мы использовали хеширование изображений для сбора более 2000 образцов для валидации. Мы удалили класс new_whale из обучающего набора данных, так как он не содержит логического смысла, который позволил бы сети отделить этот класс.

Некоторые изображения не были выровнены. К счастью, была общедоступная предварительно обученная модель детекции. Мы использовали ее, чтобы обнаружить точный bbox вокруг хвоста и соответственно обрезали изображения.
Из-за разной цветовой гаммы изображений все данные были преобразованы в grayscale перед тренировкой.

## Подход № 1: Сиамские сети
Нашей первой архитектурой была сиамская сеть с многочисленными backbone-архитектурами и нестандартным лоссом. 

Итак, как производилось обучение сиамской сети: мы выбирали батч, состоящий из 50% пар одинаковых китов и 50% пар разных (о том, как производился выбор, будет рассказано позже). После этого для каждой пары для каждой из двух фотографий мы применяли одну из выбранных нами архитектур (e.g. ResNet50), и получали на выходе последний activation map, который в данной архитектуре идет перед пулингом. Применив после этого GlobalAveragePooling, мы получали фич-вектор данного изображения.
Для успешной тренировки нужно посчитать лосс. Мы брали кастомный лосс, который считался так. Пусть есть два вектора x, y. Посчитаем вектора x - y, x + y, xy, |x||y|, и сконкатенируем их. К полученному тензору применим несколько полносвязных слоев, после чего применим слой Dense(1) и сигмоиду, получив на выходе вероятность. Такая сеть в итоге и училась.

Используемые нами архитектуры:
* ResNet-18, ResNet-34, Resnet-50
* SE-ResNeXt-50
* ResNet-подобная кастомная сеть.

Мы использовали hard-negative и hard-positive mining, решая задачу LAP на матрице скоров каждые 4 эпохи. 
Как это работало: итак, у нас есть N китов (N ~5000) и есть сиамская сеть, которая по паре фотографий выдает вероятность того, что это один кит. Посчитаем матрицу попарных вероятностей Mat размера NxN. Теперь допустим мы хотим получить hard-negatives, то есть сложные примеры разных китов. Сделаем это так: для всех пар одинаковых китов i, j установим Mat[i,j]=+infinity. На оставшейся матрице решим задачу Linear Assignment Problem (используем готовую реализацию scipy.optimize.linear_sum_assignment), то есть разобъем ее на пары  китов так, чтобы суммарная вероятность для всех пар была минимальна. Понятно, что именно так мы и выбираем самые сложные примеры. Чтобы облегчить обучение на начальных этапах, мы рандомизируем матрицу расстояний, прибавляя к ней нормально-распределенную другую матрицу такого-же размера.


Помимо этого использовалось прогрессивное обучение со стратегией 229x229 -> 384x384 -> 512x512. Как это работает:

Сначала обучили нашу сеть 229x229 изображениям с небольшой регуляризацией и большой скоростью обучения. После сходимости мы понижаем скорость обучения и увеличиваем регуляризацию, после чего обучаем сеть на изображениях с более высоким разрешением (например, 384x484).
Почему так можно делать? Потому что мы используем GlobalAveragePooling, а ему пофиг на размер входного тензора, он все приведет к вектору.

Аугментации состояли из: случайная яркость, гауссов шум и случайное размытие.
Еще одна аугментация связана с тем, что делая random_flip мы по сути меняем пару китов с одинаковой на неодинаковую.

Модели были оптимизированы с использованием оптимизатора Adam с начальной скоростью обучения 1e-4 уменьшали 5 раз на плато. Размер батча был равен 64.

Модели были написаны на Керасе и обучались около 2-3 дней на одной 2080Ti.


## Подход № 2: Метрическое обучение
Другим подходом, который мы использовали, был metric learning с Margin Loss (https://arxiv.org/pdf/1706.07567.pdf). Суть такая: как и в triplet loss, мы выбираем тройку примеров (одинаковый/разные), для каждой картинки прогоняем ее через backbone, получив фич-вектор. На трех векторах считаем loss (он похож на Triplet Loss) и все это оптимизируем. Мы использовали многочисленные предобученные архитектуры ImageNet, которые включали:
ResNet-50, ResNet-101, ResNet-152
DenseNet-121, DenseNet-169
Также использовалось прогрессивное обучение со стратегией 448x448 -> 672x672.

Мы использовали оптимизатор Adam, снижая скорость обучения в 10 раз каждые 100 эпох. Batch size был выбран равным 96 на протяжении всего обучения.

Из-за огромного дисбаланса классов были использованы суровые аугментации, которые включали random flip, поворот, масштабирование, размытие, освещение, контрастность, изменение насыщенности. Во время inference были вычислены L2 нормы между вектором тестового запроса и векторами объектов train сета, и в качестве прогноза ТОП-1 был выбран класс с наибольшим значением точечного произведения. Еще одна уловка, которая неявно помогла с дисбалансом классов, заключалась в усреднении векторов признаков для изображений китов, принадлежащих к одним и тем же особям.
Модели были реализованы на PyTorch и обучение длилось 2–4 дня (в зависимости от разрешения изображения) на одном Titan Xp.

## Подход № 3: Классификация по признакам
Мы также обучили модели классификации, используя ембеддинги, извлеченные из всех наших моделей и объединенные вместе (конечно, после применения PCA).
Голова для классификации состояла из двух полносвязных слоев с дропаутом между ними. Модель обучалась очень быстро, потому что мы использовали предварительно вычисленные ембеддинги.

Такой подход позволил нам получить еще более классный результат и внес еще больше разнообразия в общий ансамбль.
